{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luka-waronig/_simple_ngram_model_/blob/main/predicting_court_decisions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86o3TaRfTKa9"
      },
      "source": [
        "\n",
        "#Predicting court decisions of the European Court of Human Rights with machine learning and Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AUstsxmTbKY"
      },
      "source": [
        "##Load libraries\n",
        "First we need to load all the necessary libraries.\n",
        "We can more here when we want to add more functions as we go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQV3akjCp4Sz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #pandas library, a way to work with table full of data\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #vectorizer converting documents into tf-idf representation\n",
        "from sklearn.dummy import DummyClassifier #Dummy CLassifier, predicts something?\n",
        "from sklearn.naive_bayes import MultinomialNB #Naive Bayes classifier\n",
        "from sklearn.metrics import accuracy_score #accuracy score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK_0VKSTRfkG"
      },
      "source": [
        "##Using Google Colab\n",
        "\n",
        "If you are using Colab you will need to mount your google drive in order to be able to use the data stored in a folder google drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjjzhZcvM8bG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4594KqPE2jHc"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgAopFFQQ15o"
      },
      "source": [
        "###Load data\n",
        "\n",
        "Now let's open the file with the data. The file that we are going to be using is in .csv format. This is a table format. You can save and open .csv files with Excel. \n",
        "\n",
        "More about .csv on Wikipedia: https://en.wikipedia.org/wiki/Comma-separated_values\n",
        "\n",
        "The data is scraped from https://hudoc.echr.coe.int/.\n",
        "\n",
        "**AT HOME:** I recommend looking at the actual files on this ECtHR website to see what kind of data is available and in what format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xciKrLLMp_Kq"
      },
      "outputs": [],
      "source": [
        "#import csv with data\n",
        "dataset = pd.read_csv('/content/gdrive/MyDrive/AI and Digital Skills/data/Judgements_v_1.0.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKzz4EaJUGKY"
      },
      "source": [
        "###Inspect data\n",
        "\n",
        "First let's see what we have available in our dataset. To do so let's print the first five rows using .head()\n",
        "\n",
        "Want to see 10 rows use .head(10), etc.\n",
        "\n",
        "Note that the first row is actually 0, and not 1, this is the standard when programming in python. You will get used to it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dq7ZuwoUTZD"
      },
      "outputs": [],
      "source": [
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll-Ps_vsVTrJ"
      },
      "source": [
        "The rows are two long, so we can't see the names of all the columns, so let's instead print all the information available for one of the cases. Let's use case in row number 2 for that (application number 001-57518, CASE OF LAWLESS v. IRELAND)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERI7HjRAV16d"
      },
      "outputs": [],
      "source": [
        "dataset.loc[2,]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5fwCqCcVA-0"
      },
      "source": [
        "What types of variable do you see?\n",
        "\n",
        "**AT HOME:** Do they all make sense to you?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAkldQVzWjDk"
      },
      "source": [
        "Now we see the all the column names but not the full text within each cell. To inspect those we can specify the specific column we want to look at:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq2Asc-KWvJ6"
      },
      "outputs": [],
      "source": [
        "dataset.loc[2,'facts']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jdwvzZpbICi"
      },
      "source": [
        "To look at the full url you can use: `dataset.loc[2,'url']`\n",
        "\n",
        "For verdict: `dataset.loc[2,'verdict']` , etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-WyzvOw2Wg5"
      },
      "source": [
        "###Select data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctv9xsfidDwP"
      },
      "source": [
        "We do not need all the data in the table for predicting court decisions. So it is easier to navigate let's make a new table with only the fact of the cases, which we are going to use as input, let's also keep the date of the judgement and the verdict, which will be the label.\n",
        "\n",
        "**AT HOME**: Whould you want to choose other columns, which ones, why?\n",
        "\n",
        "Not all rows in the table have all information (i.e., fact, date, verdict), There are many ways to deal with this, today, we are just goin to drop the rows which don't have all of the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83UfOoXhUAA7"
      },
      "outputs": [],
      "source": [
        "facts_dataset = (pd.DataFrame()\n",
        "                .assign(Date=dataset['kpdate'],           #keep the date column, so we can sort the data based on when the judgement was made\n",
        "                        Facts=dataset['facts'],           #keep the 'facts' column - this will be our main input\n",
        "                        Violation=dataset['violation'])   #keep the 'violaiton' column - this will be our label\n",
        "                .dropna()                                 #drop every row where at least one element is missing\n",
        "                .reset_index(drop=True))                  #resent the index of the table after removing the rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lry6vYque6sy"
      },
      "source": [
        "Note that we re-named some the columns, they are now called `'Date'`, `'Facts'` and `'Violation'`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw41gzE-YvCH"
      },
      "source": [
        "Let's see what the dataset with just selected columns looks like. How many cases in it now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkyLEOCS2BJ"
      },
      "outputs": [],
      "source": [
        "facts_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT3lsic1ZPQx"
      },
      "source": [
        "\n",
        "Let's look at our data more carefully. \n",
        "\n",
        "**AT HOME**: Experiment with printing the facts of different cases, and their verdicts, could you guess the court's decision based on the facts?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIo8f-j7rSaJ"
      },
      "outputs": [],
      "source": [
        "#print some data\n",
        "row_number = 33 #change this number to try other rows\n",
        "print('Facts of the case:\\n', facts_dataset.loc[row_number]['Facts'])\n",
        "print('\\n\\nVerdict:', 'violation' if facts_dataset.loc[row_number]['Violation'] == 1 else 'no violation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS5_uP_f3UfY"
      },
      "source": [
        "###Data info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMjZKeMtV8Ze"
      },
      "outputs": [],
      "source": [
        "#print some numbers\n",
        "print('Number of cases with violation:',\n",
        "      facts_dataset['Violation'].value_counts()[1])\n",
        "\n",
        "print('Number of cases without violation:',\n",
        "      facts_dataset['Violation'].value_counts()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5y0VpHGz6xK"
      },
      "source": [
        "---\n",
        "\n",
        "###Split the dataset into training and test data\n",
        "\n",
        "We want to only predict future cases to immitate how we would predict future court decision. Plus we don't want to use newer cases to predict old cases since they may be related, and that would be cheating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23E7lB7SlE6Q"
      },
      "outputs": [],
      "source": [
        "#split the data in train and test\n",
        "train = facts_dataset[(facts_dataset['Date'] < '2017-01-01')]\n",
        "test = facts_dataset[(facts_dataset['Date'] >= '2017-01-01')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EDvaOWefoXi"
      },
      "source": [
        "Print the amount of cases in training set that resulted in violation of human rights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36FC25iVnQ6o",
        "outputId": "2dc25618-2692-4002-9277-9ee97c954765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1795"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['Violation'].value_counts()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNuH7Kx8f1PN"
      },
      "source": [
        "AT HOME: try printing the amount of the cases that resulted in no violaiton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL9joMO_L4zD"
      },
      "outputs": [],
      "source": [
        "#undersampling\n",
        "train_v = train[train['Violation'] == 1]\n",
        "train_nv = train[train['Violation'] == 0]\n",
        "train_v = train_v.sample(n=len(train_nv), random_state=101)\n",
        "train = pd.concat([train_nv, train_v])\n",
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOZJkQ0UHx2j"
      },
      "outputs": [],
      "source": [
        "test_v = test[test['Violation'] == 1]\n",
        "test_nv = test[test['Violation'] == 0]\n",
        "test_v = test_v.sample(n=len(test_nv), random_state=101)\n",
        "test = pd.concat([test_nv, test_v])\n",
        "test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg8PRiQYgRnl"
      },
      "source": [
        "###Input and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzjGOIAVgeqb"
      },
      "source": [
        "Now let's create a list of all inputs (facts) for the training set `Xtrain`, and a list of labels `Ytrain`.\n",
        "\n",
        "Let's do the same for the test set, input `Xtest` and labels `Ytest`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68KbDKDepStC"
      },
      "outputs": [],
      "source": [
        "Xtrain_words = train['Facts']\n",
        "Ytrain = train['Violation']\n",
        "Xtest = test['Facts']\n",
        "Ytest = test['Violation']\n",
        "\n",
        "Xtest_text = list(test['Facts']) #AT HOME: what is this for?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-LP0o33t7Q2"
      },
      "outputs": [],
      "source": [
        "print('Number of cases in the training set:', len(Xtrain_words))\n",
        "print('Number of cases in the test set:', len(Xtest))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcuFpZad4vYw"
      },
      "source": [
        "###Create feature vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zBvJBCN4Qm"
      },
      "source": [
        "**AT HOME:** Try adding more parameters to TFidfvectorizer to see if it changes the results. You can find the parameters that you can change here:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "\n",
        "To change the parameters re-write the line that contains TfidfVectorizer(), for instance:\n",
        "\n",
        "`vectorizer = TfidfVectorizer(ngram_range=(1,2))`\n",
        "\n",
        "**Report what your best result is in class.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Wj8vaTphMz"
      },
      "outputs": [],
      "source": [
        "#encode features into vectors: tf-idf vectorizer\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
        "Xtrain = vectorizer.fit_transform(Xtrain_words)\n",
        "print('Number of features:', len(vectorizer.get_feature_names_out()))\n",
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "za9zwJUyqp2z"
      },
      "outputs": [],
      "source": [
        "#transform test set into vectors\n",
        "Xtest = vectorizer.transform(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVU-DESp48Tg"
      },
      "source": [
        "## Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJygdM_O4Xz"
      },
      "source": [
        "**You can read about all the algorithms below in the Machine Leaning for Legal Text Classification reading. Read everything until evaluation section.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyQIeSYb5AYf"
      },
      "source": [
        "###Dummy classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-RBDEpuwuri"
      },
      "outputs": [],
      "source": [
        "#Dummy classifier\n",
        "dummy_clf = DummyClassifier(strategy=\"uniform\")\n",
        "dummy_clf.fit(Xtrain, Ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3y4_xMF5E6f"
      },
      "source": [
        "#### Making a prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2QwDdnXqzxA"
      },
      "outputs": [],
      "source": [
        "#make a prediction\n",
        "Ypredict = dummy_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDf4p7ZN5NBt",
        "outputId": "2d21f657-2319-4cd8-862f-ad2754478d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: 0 \n",
            "Gold label: 0 \n",
            "\n",
            "Facts of the case:\n",
            " 6.  The applicant is a lawyer who also writes articles for various Russian law journals and online legal information databases and networks.\n",
            "7.  According to the applicant, his work usually requires extensive scientific research, including in the field of law enforcement in the Khabarovsk Region. He supported his assertion with copies of contracts with well-known Russian publishing houses and owners of a number of legal magazines, including one supervised by the Secretariat of the President of the Russian Federation. Under the contracts he undertook the task of writing articles on specific topics of legal and social interest.\n",
            "8.  Having received an assignment to write an article on prostitution and the fight against it in the Khabarovsk Region, on 12 May 2009 the applicant wrote to the head of the Khabarovsk Region police department by registered letter, asking for statistical data for his research. The relevant parts read:\n",
            "“[I am] interested in [receiving] information for the period between 2000 and 2009, in particular:\n",
            "- [information on] the number of people found administratively liable under Article 6.11 of the ... Code of Administrative Offences (prostitution), with a breakdown by sex, residence (residents of the Khabarovsk Region or visitors), nationality (nationals of the Russian Federation, foreigners or stateless persons) and the year [of the offence];\n",
            "- [information on] the number of criminal cases instituted during the above‐mentioned period under Articles 241, 242, 242.1 [and] 127.1 (cases related to sexual exploitation) of the ... Criminal Code, with a breakdown of the specific Articles ... and the year [the case was opened];\n",
            "- [information on] the number of individuals found criminally liable under Articles 241, 242, 242.1 [and] 127.1 ... of the ... Criminal Code, with a breakdown by sex, age, educational background, permanent residence (residents of the Khabarovsk Region or visitors), nationality and period [in which the crime was committed];\n",
            "- general information on sentences imposed on individuals found criminally liable under Articles 241, 242, 242.1 [and] 127.1 ... of the ... Criminal Code ‐ the types of sentences and in how many cases they were imposed, and the years [they were imposed].\n",
            "...\n",
            "[I] stress that I do not need any specific personal information about individuals found administratively or criminally liable; [I only need] general statistical information for writing a scientific article.”\n",
            "9.  It appears from an acknowledgement of receipt that the letter reached the Khabarovsk Region police department on 25 May 2009.\n",
            "10.  Under Russian law, State officials must provide a reply to letters from individuals within thirty days. In the absence of any response, on 26 June 2009 the applicant lodged a claim with the Tsentralniy District Court of Khabarovsk (“the District Court”), complaining that the police authorities had failed to provide him with the information he had requested and requesting for access. Relying on the Information Act (see below) and Article 10 of the Convention, he argued that the officials’ implied refusal to provide him with the information had been unlawful as he had not asked for access to any confidential personal information, State secrets or information related to internal police working methods. He claimed that his request had related purely to statistical data of a general nature collected by the Information Centre of the Khabarovsk Region police department (hereinafter “the Information Centre”).\n",
            "11.  On 18 July 2009 the applicant received a letter from the head of the Information Centre, notifying him that information as specific as he had asked for could only be collected on production of a written order issued by a deputy Minister of Internal Affairs, a head of a regional or municipal police department or their divisions or a prosecutor or investigator from a prosecutor’s office. The Information Centre did not collect such information at the request of private individuals. General statistical data summarised by the Information Centre was provided to the Federal Service of State Statistics and in particular its regional office for the Khabarovsk Region, to whom the applicant could apply for the statistical data.\n",
            "12.  On 19 July 2009 the applicant wrote to the Khabarovsk Region Service of State Statistics (hereinafter “the Statistics Service”) by registered letter, asking for the statistical data for his research.\n",
            "13.  On 23 July 2009 the head of the Statistics Service replied, stating that specific statistical information on the fight against prostitution had never been provided by the Khabarovsk Regional police department.\n",
            "14.  The applicant filed copies of his letters from the Information Centre and Statistics Service with the District Court.\n",
            "15.  On 4 August 2009 it dismissed the applicant’s claim on the grounds that the Information Centre was not authorised to process data requests from private individuals. Under domestic law, the Statistics Service was tasked with dissemination of official statistical data on a broad variety of subjects, including those falling within the applicant’s field of interest. It also noted that the applicant had failed to obtain the information sought from open sources, such as libraries, archives and the Internet. The District Court also stressed that the information requested did not touch upon the applicant’s rights and legitimate interests, so the authorities’ refusal to grant him access to such information had been lawful and well-founded under section 8(2) of the Information Act.\n",
            "16.  The applicant appealed, arguing, among other things, that the police authorities had exclusive possession of the information sought by him and that he had no other means, including through assistance from the Statistics Service, of obtaining the necessary data. In addition, he submitted that the fact that his rights and legitimate interests were not affected by the requested information had no bearing on the case as under Russian law, it was not only those directly concerned who were granted access to public information.\n",
            "17.  On 16 September 2009 the Khabarovsk Regional Court upheld the judgment of 4 August 2009. Relying on section 8(2) of the Information Act, it concluded that the authorities were not obliged to provide the applicant with the information as it did not touch upon his rights and legitimate interests.\n"
          ]
        }
      ],
      "source": [
        "print('Prediction:', Ypredict[22], '\\nGold label:', list(Ytest)[22], '\\n\\nFacts of the case:\\n', (Xtest_text[22]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQvtVoIOiHWW"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLhhTV8HdaLe",
        "outputId": "20a37e7d-0441-468e-fb06-62c96266549c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7294520547945206"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Naive Bayes classifier\n",
        "nb_clf = MultinomialNB()\n",
        "nb_clf.fit(Xtrain, Ytrain)\n",
        "Ypredict = nb_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ery9KcckEXZ"
      },
      "source": [
        "**AT HOME**: Why does this Naive Bayes classifier produce such a high score? You don't need to know how the model works to answer this question.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeabHjGSc4Nk"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W72y9c5DPVbf"
      },
      "source": [
        "**AT HOME:** Run the code below to see which machien algorithm works best for your data. Try changing parameters of the algorithms to get higher scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8lg62SFPlVm"
      },
      "source": [
        "### LinearSVC\n",
        "\n",
        "If you want to change parameters of the classifier you can find the ones for LinearSVC here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
        "\n",
        "To change parameter add them to the brackets in `LinearSVC()`\n",
        "\n",
        "For instance, `LinearSVC(C=10)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GtzPtSNdx-I",
        "outputId": "eceac216-d975-4627-b63b-11108f3eb837"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7277397260273972"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fast version of Linear SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "svm_clf = LinearSVC()\n",
        "svm_clf.fit(Xtrain, Ytrain)\n",
        "Ypredict = svm_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DidHRO38Q10i"
      },
      "source": [
        "### LinearSVC\n",
        "\n",
        "You can find parameters for KNN classifier here: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors\n",
        "\n",
        "**AT HOME:** Try changing the number of neighbors `KNeighborsClassifier()`\n",
        "\n",
        "For instance, `KNeighborsClassifier(n_neighbors=10)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klwjgQcPd5ph"
      },
      "outputs": [],
      "source": [
        "#KNN classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_clf.fit(Xtrain, Ytrain)\n",
        "Ypredict = knn_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E57SmPBPdnUh",
        "outputId": "42747b96-d220-43f5-9cf9-d8dc91268d43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7414383561643836"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Logistic regression classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(Xtrain, Ytrain)\n",
        "Ypredict = lr_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B78IBRIUPsr5"
      },
      "source": [
        "We haven't discussed the algorithm below, but feel free to explore yourself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ0JOfFGPqy4",
        "outputId": "9ac3c752-386c-4711-95f9-8e903a6f0805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7243150684931506"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Support vector machines classifier (with multiple kernels)\n",
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(kernel='linear')\n",
        "svm_clf.fit(Xtrain, Ytrain)\n",
        "Ypredict = svm_clf.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De86e732G2LR"
      },
      "source": [
        "### Neural Networks - Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6If4m3Q-GihJ"
      },
      "source": [
        "Chack other parameters you can try with neural network (Multilayer perceptron): https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqMZNcSCF8WT"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(solver='sgd', max_iter=1000, verbose=False)\n",
        "mlp.fit(Xtrain, Ytrain) #this will run for a looong time (reduce max_iter to make it run faster, but it will probably impact the performance)\n",
        "Ypredict = mlp.predict(Xtest)\n",
        "accuracy_score(Ytest, Ypredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn5P9_7KHij7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}